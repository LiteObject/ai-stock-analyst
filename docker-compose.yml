version: "3.8"

services:
  ai-stock-analyst:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-stock-analyst
    environment:
      - FINANCIAL_DATASETS_API_KEY=${FINANCIAL_DATASETS_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gpt-4o}
      - CACHE_ENABLED=${CACHE_ENABLED:-true}
      - CACHE_TTL_HOURS=${CACHE_TTL_HOURS:-24}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      # Persist cache between runs
      - cache-data:/app/.cache
      # Mount local .env file (optional, for development)
      - ./.env:/app/.env:ro
    stdin_open: true
    tty: true
    # Run the stock analyst for a specific ticker
    # Override with: docker-compose run ai-stock-analyst python src/main.py --ticker AAPL
    command: ["python", "src/main.py", "--help"]

  # Development service with source code mounted
  dev:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-stock-analyst-dev
    environment:
      - FINANCIAL_DATASETS_API_KEY=${FINANCIAL_DATASETS_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gpt-4o}
      - CACHE_ENABLED=${CACHE_ENABLED:-true}
      - CACHE_TTL_HOURS=${CACHE_TTL_HOURS:-24}
      - LOG_LEVEL=${LOG_LEVEL:-DEBUG}
    volumes:
      - ./src:/app/src
      - ./tests:/app/tests
      - cache-data:/app/.cache
      - ./.env:/app/.env:ro
    stdin_open: true
    tty: true
    command: ["bash"]

  # Test runner service
  test:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-stock-analyst-test
    environment:
      - CACHE_ENABLED=false
      - LOG_LEVEL=WARNING
    volumes:
      - ./src:/app/src
      - ./tests:/app/tests
    command: ["python", "-m", "pytest", "tests/", "-v", "--tb=short"]

volumes:
  cache-data:
    driver: local
